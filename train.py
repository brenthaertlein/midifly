""" This module prepares midi file data and feeds it to the neural
    network for training """
import argparse
import pickle

import numpy
from keras.callbacks import ModelCheckpoint
from keras.layers import Activation
from keras.layers import BatchNormalization as BatchNorm
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import LSTM
from keras.models import Sequential
from keras.utils import np_utils


def train_network(name, notes_path, weights_path, sequence_length, batch_size, epochs):
    """ Train a Neural Network to generate music """

    print(f"Setting up training for {name}")

    print(f"Loading notes from {notes_path}")
    with open(notes_path, 'rb') as filepath:
        notes = pickle.load(filepath)

    # get amount of pitch names
    n_vocab = len(set(notes))

    network_input, network_output = prepare_sequences(notes, n_vocab, sequence_length)

    model = create_network(network_input, n_vocab)

    if weights_path != "":
        print(f"Loading weights from {weights_path}")
        model.load_weights(weights_path)

    train(name, model, network_input, network_output, batch_size, epochs)


def prepare_sequences(notes, n_vocab, sequence_length):
    """ Prepare the sequences used by the Neural Network """

    print('Preparing sequences')
    # get all pitch names
    pitchnames = sorted(set(item for item in notes))

    print(f'Retrieved {len(pitchnames)} notes')

    # create a dictionary to map pitches to integers
    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))

    network_input = []
    network_output = []

    # create input sequences and the corresponding outputs
    for i in range(0, len(notes) - sequence_length, 1):
        sequence_in = notes[i:i + sequence_length]
        sequence_out = notes[i + sequence_length]
        network_input.append([note_to_int[char] for char in sequence_in])
        network_output.append(note_to_int[sequence_out])

    n_patterns = len(network_input)

    print(f'Serialized data length: {len(notes)}')
    print(f'Sequence length: {sequence_length}')
    print(f'Number of patterns: {n_patterns}')

    # reshape the input into a format compatible with LSTM layers
    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))
    # normalize input
    network_input = network_input / float(n_vocab)

    network_output = np_utils.to_categorical(network_output)

    return network_input, network_output


def create_network(network_input, n_vocab):
    """ create the structure of the neural network """
    print(f"Creating Long short-term memory model")
    model = Sequential()
    model.add(LSTM(
        512,
        input_shape=(network_input.shape[1], network_input.shape[2]),
        recurrent_dropout=0.3,
        return_sequences=True
    ))
    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3, ))
    model.add(LSTM(512))
    model.add(BatchNorm())
    model.add(Dropout(0.3))
    model.add(Dense(256))
    model.add(Activation('relu'))
    model.add(BatchNorm())
    model.add(Dropout(0.3))
    model.add(Dense(n_vocab))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

    return model


def train(name, model, network_input, network_output, batch_size, epochs):
    """ train the neural network """
    dirpath = "data/weights/%s" % name
    filepath = "%s/{epoch:02d}-{loss:.4f}.hdf5" % dirpath
    checkpoint = ModelCheckpoint(
        filepath,
        monitor='loss',
        verbose=0,
        save_best_only=True,
        mode='min'
    )
    callbacks_list = [checkpoint]

    print(f'Beginning training, weights will be stored in {dirpath}')

    model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('name', help='Name this dataset')
    parser.add_argument('notes', help='Path to notes created by parse_songs.py')
    parser.add_argument('--weights', type=str, default="", help='Path to weights generated by train.py')
    parser.add_argument('--sequence-length', type=int, default=100, help='Length of the sequence to use for training')
    parser.add_argument('--batch-size', type=int, default=128, help='Size of a batch for training')
    parser.add_argument('--epochs', type=int, default=100, help='Number of epochs for training')

    args = parser.parse_args()
    train_network(
        name=args.name,
        notes_path=args.notes,
        weights_path=args.weights,
        sequence_length=args.sequence_length,
        batch_size=args.batch_size,
        epochs=args.epochs
    )
